{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ebb7fd2-1e44-486f-af66-431dc86fde42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from random_forest_cart import RandomForestCART\n",
    "from random_forest_cart import CARTTree\n",
    "# Load the trained model and preprocessing tools\n",
    "rf = joblib.load(\"random_forest_cart.pkl\")\n",
    "vectorizer = joblib.load(\"vectorizer.pkl\")\n",
    "selector = joblib.load(\"selector.pkl\")\n",
    "scaler = joblib.load(\"scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ddc2b7d-3602-4392-99ad-4c5fbb72af14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "\n",
    "# Define the function to fetch and preprocess data\n",
    "def preprocessing_dataset():\n",
    "    print(\"Taking data from dataset...\")\n",
    "    try:\n",
    "        GenderData = pd.read_csv(\"DatasetGenderNeededClarify.csv\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fetch data: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        print(\"Data get!\")\n",
    "\n",
    "    # Drop null values in 'CustomerName'\n",
    "    print(\"Cleaning data...\")\n",
    "    GenderData = GenderData.dropna(subset=['CustomerName'])\n",
    "    print(\"Data successfully cleaned!\")\n",
    "\n",
    "    # Function to split names\n",
    "    def split_name(name):\n",
    "        name = name.lower()\n",
    "        parts = name.split()\n",
    "        \n",
    "        first_name = second_name = third_name = fourth_name = last_name = ' '\n",
    "        \n",
    "        if len(parts) >= 1:\n",
    "            first_name = parts[0]\n",
    "        if len(parts) >= 2:\n",
    "            second_name = parts[1]\n",
    "        if len(parts) >= 3:\n",
    "            third_name = parts[2]\n",
    "        if len(parts) >= 4:\n",
    "            fourth_name = parts[3]\n",
    "        if len(parts) >= 5:\n",
    "            last_name = ' '.join(parts[4:])\n",
    "        \n",
    "        return pd.Series([first_name, second_name, third_name, fourth_name, last_name])\n",
    "    \n",
    "    # Apply function to DataFrame\n",
    "    print(\"Splitting customer names into individual parts...\")\n",
    "    GenderData[['FirstName', 'SecondName', 'ThirdName', 'FourthName', 'LastName']] = GenderData['CustomerName'].apply(split_name)\n",
    "    print(\"Name splitting completed!\")\n",
    "\n",
    "    # Drop original 'CustomerName' and 'Gender' columns\n",
    "    columns_to_drop = ['CustomerName', 'Gender']\n",
    "    GenderData = GenderData.drop(columns=columns_to_drop, errors='ignore')\n",
    "    \n",
    "    print(\"Preprocessing completed successfully!\")\n",
    "\n",
    "    return GenderData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b20864d-35f5-4862-8cc6-03205b352f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "\n",
    "# Define the function to fetch and preprocess data\n",
    "def preprocessing_dataset():\n",
    "    print(\"Connecting to SQL Server...\")\n",
    "    try:\n",
    "        # Define connection string (replace with your actual SQL Server details)\n",
    "        conn = pyodbc.connect(\n",
    "            \"DRIVER={SQL Server};\"\n",
    "            \"SERVER=10.12.30.240;\"\n",
    "            \"DATABASE=GORPDWHBI;\"  # Replace with your database name\n",
    "            \"UID=viewer;\"\n",
    "            \"PWD=viewer1;\"\n",
    "        )\n",
    "        print(\"Successfully connected to SQL Server!\")\n",
    "\n",
    "        # Query to fetch the required columns\n",
    "        query = \"\"\"\n",
    "        WITH RankedCustomers AS (\n",
    "            SELECT \n",
    "            CustomerId, \n",
    "            CustomerName, \n",
    "            Gender,\n",
    "                ROW_NUMBER() OVER (PARTITION BY CustomerName ORDER BY CustomerId ASC) AS row_num\n",
    "            FROM dbo.DimCustomer\n",
    "            WHERE Gender NOT IN ('F', 'M')\n",
    "        )\n",
    "        SELECT CustomerId, CustomerName, Gender \n",
    "        FROM RankedCustomers\n",
    "        WHERE row_num = 1; \n",
    "         \"\"\"\n",
    "        print(\"Processing query...\")\n",
    "\n",
    "        # Read the data from SQL Server\n",
    "        GenderData = pd.read_sql(query, conn)\n",
    "        print(\"Successfully fetched data from SQL Server!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to connect or fetch data: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        # Close connection\n",
    "        conn.close()\n",
    "        print(\"Connection closed.\")\n",
    "\n",
    "    # Drop null values in 'CustomerName'\n",
    "    print(\"Cleaning data...\")\n",
    "    GenderData = GenderData.dropna(subset=['CustomerName'])\n",
    "    print(\"Data successfully cleaned!\")\n",
    "\n",
    "    # Function to split names\n",
    "    def split_name(name):\n",
    "        name = name.lower()\n",
    "        parts = name.split()\n",
    "        \n",
    "        first_name = second_name = third_name = fourth_name = last_name = ' '\n",
    "        \n",
    "        if len(parts) >= 1:\n",
    "            first_name = parts[0]\n",
    "        if len(parts) >= 2:\n",
    "            second_name = parts[1]\n",
    "        if len(parts) >= 3:\n",
    "            third_name = parts[2]\n",
    "        if len(parts) >= 4:\n",
    "            fourth_name = parts[3]\n",
    "        if len(parts) >= 5:\n",
    "            last_name = ' '.join(parts[4:])\n",
    "        \n",
    "        return pd.Series([first_name, second_name, third_name, fourth_name, last_name])\n",
    "    \n",
    "    # Apply function to DataFrame\n",
    "    print(\"Splitting customer names into individual parts...\")\n",
    "    GenderData[['FirstName', 'SecondName', 'ThirdName', 'FourthName', 'LastName']] = GenderData['CustomerName'].apply(split_name)\n",
    "    print(\"Name splitting completed!\")\n",
    "\n",
    "    # Drop original 'CustomerName' and 'Gender' columns\n",
    "    columns_to_drop = ['CustomerName', 'Gender']\n",
    "    GenderData = GenderData.drop(columns=columns_to_drop, errors='ignore')\n",
    "    \n",
    "    print(\"Preprocessing completed successfully!\")\n",
    "\n",
    "    return GenderData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a15b6f3a-36c4-46ad-8d87-9f3f1be04ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def run_prediction():\n",
    "    print(\"Starting the prediction process...\")\n",
    "\n",
    "    # Log execution time\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"Script executed at: {timestamp}\")\n",
    "\n",
    "    try:\n",
    "        # Fetch and preprocess data\n",
    "        print(\"Fetching and preprocessing dataset from SQL Server...\")\n",
    "        GenderData = preprocessing_dataset()\n",
    "        if GenderData is None or GenderData.empty:\n",
    "            print(\"No data retrieved. Exiting process.\")\n",
    "            return\n",
    "        print(\"Data fetched and preprocessed successfully!\")\n",
    "\n",
    "        def get_bigrams(name):\n",
    "            return ' '.join(name[i:i+2] for i in range(len(name)-1)) if isinstance(name, str) else \"\"\n",
    "\n",
    "        # Join all name columns into a single column\n",
    "        X_new = GenderData[['FirstName', 'SecondName', 'ThirdName', 'FourthName', 'LastName']].astype(str)\n",
    "        GenderData[\"CustomerName\"] = X_new.apply(lambda row: ' '.join(row).strip(), axis=1)\n",
    "\n",
    "        # Extract bigrams\n",
    "        print(\"Extracting bigrams...\")\n",
    "        X_new = X_new.map(get_bigrams)\n",
    "        X_new[\"FullName\"] = X_new.apply(lambda row: ' '.join(row), axis=1)\n",
    "        print(\"Bigrams extracted!\")\n",
    "\n",
    "        # Apply HashingVectorizer\n",
    "        print(\"Applying feature transformation...\")\n",
    "        X_new_hashed = vectorizer.transform(X_new[\"FullName\"])  \n",
    "        X_new_df = pd.DataFrame(X_new_hashed.toarray())\n",
    "        print(\"Feature transformation completed!\")\n",
    "\n",
    "        # Remove low-variance features\n",
    "        print(\"Removing low-variance features...\")\n",
    "        X_new_df = pd.DataFrame(selector.transform(X_new_df))\n",
    "        print(\"Low-variance features removed!\")\n",
    "\n",
    "        # Scale features\n",
    "        print(\"Scaling features...\")\n",
    "        X_new_scaled = scaler.transform(X_new_df)\n",
    "        print(\"Feature scaling completed!\")\n",
    "\n",
    "        # Predict using the trained model\n",
    "        print(\"Model is predicting genders...\")\n",
    "        y_pred_new = rf.predict(X_new_scaled)\n",
    "        print(\"Prediction completed!\")\n",
    "\n",
    "        # Map predictions back to 'M' and 'F'\n",
    "        print(\"Mapping predictions to labels...\")\n",
    "        GenderData[\"Predicted_Gender\"] = np.where(y_pred_new == 0, 'M', 'F')\n",
    "        GenderData = GenderData[[\"CustomerName\", \"Predicted_Gender\"]]\n",
    "        print(\"Mapping completed!\")\n",
    "\n",
    "        # Show preview of mapped data\n",
    "        print(\"Preview of predicted data:\")\n",
    "        print(GenderData.head(10))  # Show first 10 rows\n",
    "        \n",
    "        # Save output\n",
    "        output_filename = f\"GenderData_Predicted_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "        GenderData.head(100).to_csv(output_filename, index=False)\n",
    "        print(f\"Predicted data (first 100 rows) saved successfully as {output_filename}!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "    print(\"Prediction process completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34788ca-9101-4a33-ae8e-1df41dd95f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def run_prediction():\n",
    "    print(\"Starting the prediction process...\")\n",
    "\n",
    "    # Log execution time\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"Script executed at: {timestamp}\")\n",
    "\n",
    "    try:\n",
    "        # Fetch and preprocess data\n",
    "        print(\"Fetching and preprocessing dataset from SQL Server...\")\n",
    "        GenderData = preprocessing_dataset()\n",
    "        if GenderData is None or GenderData.empty:\n",
    "            print(\"No data retrieved. Exiting process.\")\n",
    "            return\n",
    "        print(\"Data fetched and preprocessed successfully!\")\n",
    "\n",
    "        def get_bigrams(name):\n",
    "            return ' '.join(name[i:i+2] for i in range(len(name)-1)) if isinstance(name, str) else \"\"\n",
    "\n",
    "\n",
    "        # Join all name columns into a single column\n",
    "        X_new = GenderData[['FirstName', 'SecondName', 'ThirdName', 'FourthName', 'LastName']].astype(str)\n",
    "        GenderData[\"CustomerName\"] = X_new.apply(lambda row: ' '.join(row).strip(), axis=1)\n",
    "\n",
    "        # Extract bigrams\n",
    "        print(\"Extracting bigrams...\")\n",
    "        X_new = X_new.map(get_bigrams)\n",
    "        X_new[\"FullName\"] = X_new.apply(lambda row: ' '.join(row), axis=1)\n",
    "        print(\"Bigrams extracted!\")\n",
    "\n",
    "        # Apply HashingVectorizer\n",
    "        print(\"Applying feature transformation...\")\n",
    "        X_new_hashed = vectorizer.transform(X_new[\"FullName\"])  \n",
    "        X_new_df = pd.DataFrame(X_new_hashed.toarray())\n",
    "        print(\"Feature transformation completed!\")\n",
    "\n",
    "        # Remove low-variance features\n",
    "        print(\"Removing low-variance features...\")\n",
    "        X_new_df = pd.DataFrame(selector.transform(X_new_df))\n",
    "        print(\"Low-variance features removed!\")\n",
    "\n",
    "        # Scale features\n",
    "        print(\"Scaling features...\")\n",
    "        X_new_scaled = scaler.transform(X_new_df)\n",
    "        print(\"Feature scaling completed!\")\n",
    "\n",
    "        # Predict using the trained model\n",
    "        print(\"Model is predicting genders...\")\n",
    "        y_pred_new = rf.predict(X_new_scaled)\n",
    "        print(\"Prediction completed!\")\n",
    "\n",
    "        # Map predictions back to 'M' and 'F'\n",
    "        print(\"Mapping predictions to labels...\")\n",
    "        GenderData[\"Predicted_Gender\"] = np.where(y_pred_new == 0, 'M', 'F')\n",
    "        GenderData = GenderData[[\"CustomerName\", \"Predicted_Gender\"]]\n",
    "        print(\"Mapping completed!\")\n",
    "\n",
    "        # Show preview of mapped data\n",
    "        print(\"Preview of predicted data:\")\n",
    "        print(GenderData.head())  # Show first 5 rows\n",
    "        conn = pyodbc.connect(\n",
    "            \"DRIVER={SQL Server};\"\n",
    "            \"SERVER=10.12.30.240;\"\n",
    "            \"DATABASE=GORPDWHBI;\"\n",
    "            \"UID=viewer;\"\n",
    "            \"PWD=viewer1;\"\n",
    "        )\n",
    "        \n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Ensure no NaN values\n",
    "        GenderData = GenderData.dropna(subset=[\"CustomerName\", \"Predicted_Gender\"])\n",
    "        \n",
    "        # Loop through DataFrame rows and insert into SQL Server\n",
    "        print(\"Inserting predicted data into SQL Server...\")\n",
    "        for index, row in GenderData.iterrows():\n",
    "            cursor.execute(\n",
    "                \"INSERT INTO YourTableName (CustomerName, Gender) VALUES (?, ?)\",\n",
    "                row[\"CustomerName\"], row[\"Predicted_Gender\"]\n",
    "            )\n",
    "        \n",
    "        conn.commit()\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        print(\"Data inserted successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "    print(\"Prediction process completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f80e723-70e7-4a39-a200-4cc2f95691be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def run_prediction():\n",
    "    print(\"Starting the prediction process...\")\n",
    "\n",
    "    # Log execution time\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"Script executed at: {timestamp}\")\n",
    "\n",
    "    try:\n",
    "        # Fetch and preprocess data\n",
    "        print(\"Fetching and preprocessing dataset from SQL Server...\")\n",
    "        GenderData = preprocessing_dataset()\n",
    "        if GenderData is None or GenderData.empty:\n",
    "            print(\"No data retrieved. Exiting process.\")\n",
    "            return\n",
    "        print(\"Data fetched and preprocessed successfully!\")\n",
    "\n",
    "        def get_bigrams(name):\n",
    "            return ' '.join(name[i:i+2] for i in range(len(name)-1)) if isinstance(name, str) else \"\"\n",
    "\n",
    "\n",
    "        # Join all name columns into a single column\n",
    "        X_new = GenderData[['FirstName', 'SecondName', 'ThirdName', 'FourthName', 'LastName']].astype(str)\n",
    "        GenderData[\"CustomerName\"] = X_new.apply(lambda row: ' '.join(row).strip(), axis=1)\n",
    "\n",
    "        # Extract bigrams\n",
    "        print(\"Extracting bigrams...\")\n",
    "        X_new = X_new.map(get_bigrams)\n",
    "        X_new[\"FullName\"] = X_new.apply(lambda row: ' '.join(row), axis=1)\n",
    "        print(\"Bigrams extracted!\")\n",
    "\n",
    "        # Apply HashingVectorizer\n",
    "        print(\"Applying feature transformation...\")\n",
    "        X_new_hashed = vectorizer.transform(X_new[\"FullName\"])  \n",
    "        X_new_df = pd.DataFrame(X_new_hashed.toarray())\n",
    "        print(\"Feature transformation completed!\")\n",
    "\n",
    "        # Remove low-variance features\n",
    "        print(\"Removing low-variance features...\")\n",
    "        X_new_df = pd.DataFrame(selector.transform(X_new_df))\n",
    "        print(\"Low-variance features removed!\")\n",
    "\n",
    "        # Scale features\n",
    "        print(\"Scaling features...\")\n",
    "        X_new_scaled = scaler.transform(X_new_df)\n",
    "        print(\"Feature scaling completed!\")\n",
    "\n",
    "        # Predict using the trained model\n",
    "        print(\"Model is predicting genders...\")\n",
    "        y_pred_new = rf.predict(X_new_scaled)\n",
    "        print(\"Prediction completed!\")\n",
    "\n",
    "        # Map predictions back to 'M' and 'F'\n",
    "        print(\"Mapping predictions to labels...\")\n",
    "        GenderData[\"Predicted_Gender\"] = np.where(y_pred_new == 0, 'M', 'F')\n",
    "        GenderData = GenderData[[\"CustomerName\", \"Predicted_Gender\"]]\n",
    "        print(\"Mapping completed!\")\n",
    "\n",
    "        # Show preview of mapped data\n",
    "        print(\"Preview of predicted data:\")\n",
    "        print(GenderData.head())  # Show first 5 rows\n",
    "        conn = pyodbc.connect(\n",
    "            \"DRIVER={SQL Server};\"\n",
    "            \"SERVER=10.12.30.240;\"\n",
    "            \"DATABASE=GORPDWHBI;\"\n",
    "            \"UID=viewer;\"\n",
    "            \"PWD=viewer1;\"\n",
    "        )\n",
    "        \n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Ensure no NaN values\n",
    "        GenderData = GenderData.dropna(subset=[\"CustomerName\", \"Predicted_Gender\"])\n",
    "        \n",
    "        # Loop through DataFrame rows and insert into SQL Server\n",
    "        print(\"Inserting predicted data into SQL Server...\")\n",
    "        for index, row in GenderData.iterrows():\n",
    "            cursor.execute(\"\"\"\n",
    "                MERGE INTO dbo.MemberGenderPrediction AS target\n",
    "                USING (SELECT ? AS CustomerName, ? AS GenderPrediction) AS source\n",
    "                ON target.CustomerName = source.CustomerName\n",
    "                WHEN NOT MATCHED THEN\n",
    "                    INSERT (CustomerName, GenderPrediction) VALUES (source.CustomerName, source.GenderPrediction);\n",
    "            \"\"\", (row[\"CustomerName\"], row[\"Predicted_Gender\"]))\n",
    "\n",
    "        conn.commit()\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        print(\"Data inserted successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "    print(\"Prediction process completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c174b3d3-11f3-4a9a-95cd-c798726184a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the prediction process...\n",
      "Script executed at: 2025-02-10 09:00:08\n",
      "Fetching and preprocessing dataset from SQL Server...\n",
      "Connecting to SQL Server...\n",
      "Successfully connected to SQL Server!\n",
      "Processing query...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_19660\\974329849.py:36: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  GenderData = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully fetched data from SQL Server!\n",
      "Connection closed.\n",
      "Cleaning data...\n",
      "Data successfully cleaned!\n",
      "Splitting customer names into individual parts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "while True:\n",
    "    start_prediction_time = time.time()\n",
    "    run_prediction()\n",
    "    end_prediction_time = time.time()\n",
    "    print(f\"Testing Time: {end_prediction_time - start_prediction_time:.4f} seconds\")\n",
    "    \n",
    "    # Sleep for 15 hour (900 seconds)\n",
    "    \n",
    "    print(\"Sleeping for 15 minutes...\")\n",
    "    time.sleep(900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc027c8c-0155-474e-ae66-d5d5248e869f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
